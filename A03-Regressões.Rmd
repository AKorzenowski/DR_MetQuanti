---
title: "Métodos Quantitativos"
author: "Prof. Dr. A. L. Korzenowski"
#header-includes:
#   - \usepackage{array,xcolor,colortbl}
output: pdf_document
#lang: pt
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = 3)
options(tinytex.verbose = TRUE)
```
# Aula 03: Modelos Lineares de Regressão e Generalizados

## Multiple (Linear) Regression
A regressão linear simples é utilizada para analisar relações entre variáveis contínuas. Para fazer a regressão no R a função é **lm()**, para linear models. A seguir temos um exemplo de aplicação das funções e discutiremos os conceitos em conjunto com os resultados.

```{r Code Block 1, message=FALSE, warning=FALSE}
# Multiple Linear Regression Example 
attach(mtcars)
fit <- lm(mpg ~ hp + wt + vs, data=mtcars)
summary(fit) # show results

# Other useful functions 
coefficients(fit) # model coefficients
confint(fit, level=0.95) # CIs for model parameters 
fitted(fit) # predicted values
residuals(fit) # residuals
anova(fit) # anova table 
vcov(fit) # covariance matrix for model parameters 
influence(fit) # regression diagnostics
```

Gráficos de Diagnóstico provém avaliação de heterocedásticidade, normalidade e observações influentes (potenciais outliers). Copie e cole o seguinte código para avaliar graficamente os pressupóstos da Regressão Linear e testar a normalidade dos residuos.
```{r Code Block 2, message=FALSE, warning=FALSE, eval=FALSE}
# diagnostic plots 
layout(matrix(c(1,2,3,4),2,2)) # optional 4 graphs/page 
plot(fit)

# executando o teste de normalidade
require(nortest)
lillie.test(residuals(fit))
```

## Diagnósticos da Regressão
É possível que deseje-se maior rigos na avaliação dos pressupostos da regressão. Uma excelente revisão dos diagnósticos de regressão é fornecida por John Fox, apropriadamente chamado de [Overview of Regression Diagnostics](http://socserv.socsci.mcmaster.ca/jfox/Courses/Brazil-2009/index.html). O pacote **car** do Dr. Fox fornece utilitários avançados para modelagem de regressão.

Vamos assumir que estamos ajustando um modelo linear múltiplo nos dados da base **mtcars**.
```{r Code Block 3, message=FALSE, warning=FALSE}
require(car)
fit <- lm(mpg~disp+hp+wt+drat, data=mtcars)
```

Identificando os Outliers...
```{r Code Block 3a, message=FALSE, warning=FALSE, out.width = '50%', fig.align = "center"}
outlierTest(fit) # Bonferonni p-value for most extreme obs
qqPlot(fit, main="QQ Plot") #qq plot for studentized resid 
leveragePlots(fit) # leverage plots
```

Avaliando a influência das variáveis...
```{r Code Block 3b, message=FALSE, warning=FALSE}
# added variable plots 
avPlots(fit)
# Cook's D plot
# identify D values > 4/(n-k-1) 
cutoff <- 4/((nrow(mtcars)-length(fit$coefficients)-2)) 
plot(fit, which=4, cook.levels=cutoff)
# Influence Plot 
influencePlot(fit, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
```

Avaliando a normalidade dos resíduos...
```{r Code Block 3c, message=FALSE, warning=FALSE}
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")
# distribution of studentized residuals
require(MASS)
sresid <- studres(fit) 
hist(sresid, freq=FALSE, 
   main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40) 
yfit<-dnorm(xfit) 
lines(xfit, yfit)
```

Avaliando a heterocedasticidade...
```{r Code Block 3d, message=FALSE, warning=FALSE}
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values 
spreadLevelPlot(fit)
```

Avaliando a presença de multicolinearidade...
```{r Code Block 3e, message=FALSE, warning=FALSE}
vif(fit) # variance inflation factors 
sqrt(vif(fit)) > 2 # problem?
```

Avaliando a independência dos residuos - Erros não autocorrelacionados...
```{r Code Block 3f, message=FALSE, warning=FALSE}
durbinWatsonTest(fit)
```


### Comparando modelos
Você pode comprar modelos com a função **anova()**. O seguinte código verifica o impacto de **wt** e **vs** na predição de **mpg** em relação a um modelo que utiliza apenas **hp** como variável preditora. 

```{r Code Block 4, message=FALSE, warning=FALSE}
# compare models
fit2 <- lm(mpg ~ hp, data=mtcars)
anova(fit2,fit)
```

### Seleção de Variáveis
A seleção de um subconjunto de variáveis preditoras de um conjunto maior (por exemplo, seleção por etapas) é um tópico controverso. Você pode executar a seleção passo a passo (avançar, retroceder, ambos) usando a função **stepAIC()** do pacote **MASS**. O **stepAIC()** realiza a seleção do modelo passo a passo pelo AIC exato.

```{r Code Block 5, message=FALSE, warning=FALSE}
# Stepwise Regression
require(MASS)
fit <- lm(mpg ~ disp + hp + drat + wt + qsec + vs, data=mtcars)
step <- stepAIC(fit, direction="both")
step$anova # display results
```

Como alternativa, você pode executar a regressão de todos os subconjuntos usando a função **leaps()** do pacote **leaps**. No código a seguir, o **nbest** indica o número de subconjuntos de cada tamanho a serem relatados. Aqui, os dez melhores modelos serão relatados para cada tamanho de subconjunto (1 preditor, 2 preditores etc.). Copie e cole o código no Console do R para verificar os resultados.
```{r Code Block 6, message=FALSE, warning=FALSE, eval=FALSE}
# All Subsets Regression
require(leaps)
leaps<-regsubsets(mpg ~ disp + hp + drat + wt + qsec + vs, data=mtcars,nbest=10)
# view results 
summary(leaps)
# plot a table of models showing variables in each model.
# models are ordered by the selection statistic.
plot(leaps,scale="r2")
# plot statistic by subset size 
require(car)
subsets(leaps, statistic="rsq")
```
## Indo além...
O pacote **relaimpo** fornece medidas de importância relativa para cada um dos preditores no modelo. Consulte **help(calc.relimp)** para obter detalhes sobre as quatro medidas de importância relativa fornecidas.

## 